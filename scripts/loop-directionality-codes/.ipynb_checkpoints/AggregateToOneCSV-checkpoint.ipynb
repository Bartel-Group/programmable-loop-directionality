{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial-essay",
   "metadata": {},
   "source": [
    "#### Aggregating csv files into one file\n",
    "\n",
    "aggregate_csv_files reads all the files from the input_dir and rights the results to an output_file\n",
    "\n",
    "includes cells to separate steady-state and non steady-state data and find parameters to re-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distributed-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/panfs/jay/groups/16/dauenha0/murp1677/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/panfs/jay/groups/16/dauenha0/murp1677/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/panfs/jay/groups/16/dauenha0/murp1677/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/panfs/jay/groups/16/dauenha0/murp1677/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/panfs/jay/groups/16/dauenha0/murp1677/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/panfs/jay/groups/16/dauenha0/murp1677/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/panfs/jay/groups/16/dauenha0/murp1677/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/panfs/jay/groups/16/dauenha0/murp1677/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/panfs/jay/groups/16/dauenha0/murp1677/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `/panfs/jay/groups/16/dauenha0/murp1677/.julia/environments/v1.9/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Printf\")\n",
    "Pkg.add(\"FileIO\")\n",
    "Pkg.add(\"NBInclude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grave-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Printf, FileIO, NBInclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exterior-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"/home/dauenha0/murp1677/Cyclic_Dynamics/Code/Non-Git/RxnParameters.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sitting-monster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aggregate_csv_files (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function aggregate_csv_files(input_dir, output_file)\n",
    "    # Get a list of CSV files in the directory\n",
    "    csv_files = filter(x -> occursin(r\"\\.csv$\", x), readdir(input_dir))\n",
    "\n",
    "    # Iterate over each CSV file\n",
    "    for file in csv_files\n",
    "        # read date from the csv file\n",
    "        data = CSV.read(joinpath(input_dir, file), DataFrame)\n",
    "\n",
    "        # Write the contents to the output CSV file\n",
    "        if isfile(output_file) == false\n",
    "            # If the file does not exst, write the file including column names\n",
    "            col_names = [\"Batch ID\",\"Simulation ID\", \"alpha a\", \"alpha b\", \"alpha c\", \"beta a\", \"beta b\", \n",
    "                \"beta c\", \"gamma B-A\", \"gamma C-A\", \"delta B-A\", \"delta C-A\", \"BEa\", \"frequency [1/s]\", \n",
    "                \"ΔBEa [eV]\", \"Loop TOF [1/s]\",\"Steady State Conditon\"]; # 17 columns\n",
    "            CSV.write(output_file, data, header=col_names)\n",
    "        else    \n",
    "            CSV.write(output_file, data, append=true)\n",
    "        end\n",
    "        \n",
    "        # Delete the CSV file\n",
    "        # rm(joinpath(input_dir, file))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "interested-bruce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mthread = 1 warning: only found 2 / 17 columns around data row: 54. Filling remaining columns with `missing`\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ CSV ~/.julia/packages/CSV/7lFhM/src/file.jl:576\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mthread = 1 warning: only found 2 / 17 columns around data row: 54. Filling remaining columns with `missing`\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ CSV ~/.julia/packages/CSV/7lFhM/src/file.jl:576\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set 1 done.\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/SimulationOutputSet1\"\n",
    "output_file = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/Set1_Simulation_outputs.csv\"\n",
    "\n",
    "aggregate_csv_files(input_dir, output_file)\n",
    "println(\"set 1 done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "recorded-leeds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set 1 done.\n",
      "set 2 done.\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/SimulationOutputSet1\"\n",
    "output_file = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/Set1_Simulation_outputs.csv\"\n",
    "\n",
    "aggregate_csv_files(input_dir, output_file)\n",
    "println(\"set 1 done.\")\n",
    "\n",
    "input_dir = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/SimulationOutputSet2\"\n",
    "output_file = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/Set2_Simulation_outputs.csv\"\n",
    "\n",
    "aggregate_csv_files(input_dir, output_file)\n",
    "println(\"set 2 done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "described-rachel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.2, 0.2, 0.2, 0.6, 0.6, 0.6, 0.6, 0.6, 0.5, 0.5, 0.8, 50.0, 0.3, 0.05797767833709657, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Load Set 1\n",
    "fileName = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/Set1_Simulation_outputs.csv\"\n",
    "df_set1 = CSV.read(fileName, DataFrame)\n",
    "df_array_set1 = Matrix(df_set1)\n",
    "\n",
    "# Load Set 2\n",
    "fileName = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/Set2_Simulation_outputs.csv\"\n",
    "df_set2 = CSV.read(fileName, DataFrame)\n",
    "df_array_set2 = Matrix(df_set2)\n",
    "\n",
    "# Preallocate Array\n",
    "len = size(df_array_set1, 1) + size(df_array_set2, 1)\n",
    "combined_array = Matrix{Float64}(undef, len, 16)\n",
    "\n",
    "\n",
    "# Loop through Set 1\n",
    "for i in 1:size(df_array_set1, 1)\n",
    "    SimID = (df_array_set1[i, 1]-1) *60 + df_array_set1[i, 2]  # Convert to Int64\n",
    "    \n",
    "    if df_array_set1[i, 16] == \"Not-defined\"\n",
    "        SS_indicator = 0.0\n",
    "        loopTOF = 0.0\n",
    "        else\n",
    "        SS_indicator = 1.0\n",
    "        loopTOF = parse(Float64, df_array_set1[i, 16])\n",
    "        \n",
    "    end\n",
    "    combined_array[i, :] = vcat(SimID, df_array_set1[i, 3:15], loopTOF, SS_indicator)\n",
    "end\n",
    "\n",
    "# Loop through Set 2\n",
    "for i in 1:size(df_array_set2, 1)\n",
    "    SimID = (df_array_set2[i, 1]-1) *60 + df_array_set2[i, 2] + 90000  # Convert to Int64\n",
    "    if df_array_set2[i, 16] == \"Not-defined\"\n",
    "        SS_indicator = 0.0\n",
    "        loopTOF = 0.0\n",
    "        else\n",
    "        SS_indicator = 1.0\n",
    "        loopTOF = parse(Float64, df_array_set2[i, 16])\n",
    "    end\n",
    "    combined_array[i + size(df_array_set1, 1), :] = vcat(SimID, df_array_set2[i, 3:15], loopTOF, SS_indicator)\n",
    "end\n",
    "\n",
    "# Get permutation indices based on the first column\n",
    "perm_indices = sortperm(combined_array[:, 1])\n",
    "\n",
    "# Sort the matrix using the permutation indices\n",
    "sorted_array = combined_array[perm_indices, :]\n",
    "\n",
    "# Convert sim ID to a integer\n",
    "convert.(Int64, sorted_array[:,1])\n",
    "\n",
    "println(sorted_array[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "perceived-certification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delete_duplicates (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function delete_duplicates(matrix)\n",
    "    unique_matrix = unique(matrix, dims=1)\n",
    "    \n",
    "    # Get permutation indices based on the first column\n",
    "    perm_indices = sortperm(unique_matrix[:, 1])\n",
    "\n",
    "    # Sort the matrix using the permutation indices\n",
    "    unique_matrix = unique_matrix[perm_indices, :]\n",
    "    \n",
    "    return unique_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "future-niagara",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197506, 16)\n"
     ]
    }
   ],
   "source": [
    "unique_matrix = delete_duplicates(combined_array)\n",
    "println(size(unique_matrix))\n",
    "\n",
    "#println(unique_matrix[1:1000,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "instrumental-captain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delete_duplicates_new (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function delete_duplicates_new(matrix)\n",
    "    Sim_ID = matrix[:, 1]\n",
    "    n = length(Sim_ID)\n",
    "    \n",
    "    Sim_ID_unique = Set{eltype(Sim_ID)}()  # Preallocate Set\n",
    "    unique_matrix = Matrix{eltype(matrix)}(undef, 0, size(matrix, 2))  # Preallocate matrix\n",
    "\n",
    "    for i in 1:n\n",
    "        if !(Sim_ID[i] in Sim_ID_unique)\n",
    "            push!(Sim_ID_unique, Sim_ID[i])\n",
    "            unique_matrix = vcat(unique_matrix, matrix[i, :]')\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return unique_matrix\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_matrix_refined = delete_duplicates_new(unique_matrix)\n",
    "println(size(unique_matrix_refined))\n",
    "\n",
    "println(unique_matrix_refined[1:10,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "duplicate-tennessee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0 0.2 0.2 0.2 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.8 50.0 0.3 0.05797767833709657 1.0; 2.0 0.6 0.2 0.2 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.8 50.0 0.3 0.019739906157319985 1.0; 3.0 0.9 0.2 0.2 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.8 50.0 0.3 0.01746169936629489 1.0; 4.0 0.2 0.6 0.2 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.8 50.0 0.3 0.05797767833709657 1.0; 5.0 0.6 0.6 0.2 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.8 50.0 0.3 0.019739906157319985 1.0; 6.0 0.9 0.6 0.2 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.8 50.0 0.3 0.01746169936629489 1.0; 7.0 0.2 0.9 0.2 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.8 50.0 0.3 0.05797767833709657 1.0; 8.0 0.6 0.9 0.2 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.8 50.0 0.3 0.019739906157319985 1.0; 9.0 0.9 0.9 0.2 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.8 50.0 0.3 0.01746169936629489 1.0; 10.0 0.2 0.2 0.6 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.8 50.0 0.3 0.014051438664920401 1.0]\n"
     ]
    }
   ],
   "source": [
    "println(unique_matrix_refined[1:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "mediterranean-joining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2024-03-12_ALL_Simulation_outputs.csv\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df = DataFrame(unique_matrix_refined, :auto) \n",
    "\n",
    "fpathSS = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2024-03-13_ALL_Simulation_outputs.csv\"\n",
    "if isfile(fpathSS) == false # checks if file exists\n",
    "    # if file does NOT exist, write file and include column names\n",
    "    col_names = [\"Simulation ID\", \"alpha a\", \"alpha b\", \"alpha c\", \"beta a\", \"beta b\", \"beta c\", \"gamma B-A\", \"gamma C-A\", \"delta B-A\", \"delta C-A\", \"BEa\", \"frequency [1/s]\", \"ΔBEa [eV]\", \"Loop TOF [1/s]\",\"Steady State Conditon\"];\n",
    "    CSV.write(fpathSS, unique_df, header=col_names)\n",
    "else \n",
    "    CSV.write(fpathSS, unique_df, append=true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "designing-premium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2024-02-27_ALL_Simulation_outputs_RATECONSTANTS.csv\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse Data\n",
    "loopTOF = unique_df[:,15];\n",
    "len = length(loopTOF)\n",
    "\n",
    "# Preallocate Arrays \n",
    "alpha = Matrix{Float64}(undef,len,3)\n",
    "beta = Matrix{Float64}(undef,len,3)\n",
    "gamma = Matrix{Float64}(undef,len,2)\n",
    "delta = Matrix{Float64}(undef,len,2)\n",
    "\n",
    "alpha[:,1] = unique_df[:,2];\n",
    "alpha[:,2] = unique_df[:,3];\n",
    "alpha[:,3] = unique_df[:,4];\n",
    "\n",
    "beta[:,1] = unique_df[:,5];\n",
    "beta[:,2] = unique_df[:,6];\n",
    "beta[:,3] = unique_df[:,7];\n",
    "\n",
    "gamma[:,1] = unique_df[:,8];\n",
    "gamma[:,2] = unique_df[:,9];\n",
    "\n",
    "delta[:,1] = unique_df[:,10];\n",
    "delta[:,2] = unique_df[:,11];\n",
    "\n",
    "BEa = unique_df[:,12];\n",
    "delBEa = unique_df[:,14];\n",
    "freq = unique_df[:,13];\n",
    "SimID = unique_df[:,1];\n",
    "SS_cond = unique_df[:,16];\n",
    "\n",
    "# define each state\n",
    "k1 = Matrix{Float64}(undef,len,6)\n",
    "k2 = Matrix{Float64}(undef,len,6)\n",
    "\n",
    "for i in range(1,len)\n",
    "    # State 1\n",
    "    kf1, kr1, BE1 = RxnParametersArray(BEa[i], gamma[i,:], delta[i,:], alpha[i,:], beta[i,:]);\n",
    "    \n",
    "    # State 2\n",
    "    kf2, kr2, BE2 = RxnParametersArray((BEa[i]+delBEa[i]), gamma[i,:], delta[i,:], alpha[i,:], beta[i,:]);\n",
    "    \n",
    "    k1[i,:] = vcat(kf1,kr1)\n",
    "    k2[i,:] = vcat(kf2,kr2)\n",
    "end\n",
    "\n",
    "rate_df = DataFrame(SimID = SimID, kf1_1 = k1[:,1], kf2_1 = k1[:,2], kf3_1 = k1[:,3], \n",
    "    kr1_1 = k1[:,4], kr2_1 = k1[:,5], kr3_1 = k1[:,6], kf1_2 = k2[:,1], kf2_2 = k2[:,2],\n",
    "    kf3_2 = k2[:,3], kr1_2 = k2[:,4], kr2_2 = k2[:,5], kr3_2 = k2[:,6], frequency = freq, \n",
    "    ΔBEa = delBEa, Loop_TOF = loopTOF, Steady_State = SS_cond)\n",
    "\n",
    "fpath = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2024-03-10_ALL_Simulation_outputs_RATECONSTANTS.csv\"\n",
    "if isfile(fpath) == false # checks if file exists\n",
    "    # if file does NOT exist, write file and include column names\n",
    "    col_names = [\"Simulation ID\", \"k1 state 1\", \"k2 state 1\", \"k3 state 1\", \"k-1 state 1\", \"k-2 state 1\", \n",
    "        \"k-3 state 1\", \"k1 state 2\", \"k2 state 2\", \"k3 state 2\", \"k-1 state 2\", \"k-2 state 2\", \n",
    "        \"k-3 state 2\", \"frequency [1/s]\", \"ΔBEa [eV]\", \"Loop TOF [1/s]\",\"Steady State Conditon\"];\n",
    "    CSV.write(fpath, rate_df, header=col_names)\n",
    "else \n",
    "    CSV.write(fpath, rate_df, append=true)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-twenty",
   "metadata": {},
   "source": [
    "## Old Code cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "accomplished-evaluation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delete_duplicates_new (generic function with 1 method)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function delete_duplicates_new(matrix)\n",
    "    unique_indices = Set()\n",
    "\n",
    "    # Create a new matrix with unique rows\n",
    "    unique_matrix = filter(row -> begin\n",
    "        value = row[1]\n",
    "        if !(value in unique_indices)\n",
    "            push!(unique_indices, value)\n",
    "            return true\n",
    "        else\n",
    "            return false\n",
    "        end\n",
    "    end, eachrow(matrix))\n",
    "\n",
    "    return unique_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "persistent-documentary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delete_duplicates_new (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function delete_duplicates_new(matrix)\n",
    "    Sim_ID = matrix[:, 1]\n",
    "    Sim_ID_unique = []\n",
    "    unique_matrix = []\n",
    "    \n",
    "for i in 1:length(Sim_ID)\n",
    "    if Sim_ID[i] in Set(Sim_ID_unique)\n",
    "        # Value is already in Sim_ID_unique, do something if needed\n",
    "    else\n",
    "        push!(Sim_ID_unique, Sim_ID[i])\n",
    "        push!(unique_matrix, matrix[i, :])\n",
    "    end\n",
    "end\n",
    "    \n",
    "    return unique_matrix\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "plastic-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2023-09-07_CompiledResults\"\n",
    "output_file = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2023-09-07_Simulation_outputs.csv\"\n",
    "\n",
    "aggregate_csv_files(input_dir, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "iraqi-haven",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/MachineLearning/aggregate_Results.csv\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fpath = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/MachineLearning/aggregate_Results.csv\"\n",
    "if isfile(fpath) == false # checks if file exists\n",
    "    # if file does NOT exist, write file and include column names\n",
    "    col_names = [\"Simulation ID\", \"alpha a\", \"alpha b\", \"alpha c\", \"beta a\", \"beta b\", \"beta c\", \"gamma B-A\", \"gamma C-A\", \"delta B-A\", \"delta C-A\", \"BEa\", \"frequency [1/s]\", \"ΔBEa [eV]\", \"Loop TOF [1/s]\" ]; # 12 columns\n",
    "    CSV.write(fpath,df_all, header=col_names)\n",
    "else \n",
    "    CSV.write(fpath,df_all, append=true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afraid-uganda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96910\n",
      "17998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96910×16 Matrix{Any}:\n",
       "      1  0.2  0.2  0.2  0.6  0.6  0.6  …  0.5  0.8  50.0  0.3  -49.9926  1.0\n",
       "      2  0.2  0.2  0.2  0.6  0.6  0.6     0.5  0.8  50.0  0.3  -49.9721  1.0\n",
       "      3  0.2  0.2  0.2  0.6  0.6  0.6     0.5  0.8  50.0  0.3  -49.9012  1.0\n",
       "      4  0.2  0.2  0.2  0.6  0.6  0.6     0.5  0.8  50.0  0.3  -49.6861  1.0\n",
       "      5  0.2  0.2  0.2  0.6  0.6  0.6     0.5  0.8  50.0  0.3  -49.6345  1.0\n",
       "      6  0.2  0.2  0.2  0.6  0.6  0.6  …  0.5  0.8  50.0  0.3  -49.4099  1.0\n",
       "      7  0.2  0.2  0.2  0.6  0.6  0.6     0.5  0.8  50.0  0.3  -49.3647  1.0\n",
       "      8  0.2  0.2  0.2  0.6  0.6  0.6     0.5  0.8  50.0  0.3  -49.2679  1.0\n",
       "      9  0.2  0.2  0.2  0.6  0.6  0.6     0.5  0.8  50.0  0.3  -49.2619  1.0\n",
       "     10  0.2  0.2  0.2  0.6  0.6  0.6     0.5  0.8  50.0  0.3  -49.2444  1.0\n",
       "     11  0.2  0.2  0.2  0.6  0.6  0.6  …  0.5  0.8  50.0  0.3  -49.1556  1.0\n",
       "     12  0.2  0.2  0.2  0.6  0.6  0.6     0.5  0.8  50.0  0.3  -48.7946  1.0\n",
       "     13  0.2  0.2  0.2  0.6  0.6  0.6     0.5  0.8  50.0  0.3  -48.6608  1.0\n",
       "      ⋮                      ⋮         ⋱  ⋮                              ⋮\n",
       " 174265  0.9  0.9  0.9  1.2  1.2  1.2     1.5  0.8  50.0  0.8   49.8199  1.0\n",
       " 174266  0.9  0.9  0.9  1.2  1.2  1.2     1.5  0.8  50.0  0.8   49.864   1.0\n",
       " 174267  0.9  0.9  0.9  1.2  1.2  1.2  …  1.5  0.8  50.0  0.8   49.8647  1.0\n",
       " 174304  0.9  0.9  0.9  1.2  1.2  1.2     1.5  0.8  50.0  0.8   49.8724  1.0\n",
       " 174305  0.9  0.9  0.9  1.2  1.2  1.2     1.5  0.8  50.0  0.8   49.8852  1.0\n",
       " 174306  0.9  0.9  0.9  1.2  1.2  1.2     1.5  0.8  50.0  0.8   49.9016  1.0\n",
       " 174307  0.9  0.9  0.9  1.2  1.2  1.2     1.5  0.8  50.0  0.8   49.9022  1.0\n",
       " 174308  0.9  0.9  0.9  1.2  1.2  1.2  …  1.5  0.8  50.0  0.8   49.9141  1.0\n",
       " 174309  0.9  0.9  0.9  1.2  1.2  1.2     1.5  0.8  50.0  0.8   49.9147  1.0\n",
       " 174310  0.9  0.9  0.9  1.2  1.2  1.2     1.5  0.8  50.0  0.8   49.9179  1.0\n",
       " 174311  0.9  0.9  0.9  1.2  1.2  1.2     1.5  0.8  50.0  0.8   49.9982  1.0\n",
       " 174312  0.9  0.9  0.9  1.2  1.2  1.2     1.5  0.8  50.0  0.8   49.9992  1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate Steady State and Non-Steady State\n",
    "\n",
    "# Preallocate Arrays\n",
    "combined_array_SS = Matrix{Any}(undef, len, 16)\n",
    "combined_array_nonSS = Matrix{Any}(undef, len, 16)\n",
    "count_SS = 0\n",
    "count_nonSS = 0\n",
    "\n",
    "for i in range(1, len)\n",
    "    if combined_array[i,16] == 1.0\n",
    "        count_SS += 1\n",
    "        combined_array_SS[count_SS,:] = combined_array[i,:]\n",
    "        combined_array_SS[count_SS,1] = Int(combined_array[i,1])\n",
    "    else\n",
    "        count_nonSS += 1\n",
    "        combined_array_nonSS[count_nonSS,:] = combined_array[i,:]\n",
    "        combined_array_nonSS[count_nonSS,1] = Int(combined_array[i,1])\n",
    "    end\n",
    "end\n",
    "println(count_SS)\n",
    "println(count_nonSS)\n",
    "# remove undefined elements\n",
    "combined_array_nonSS = combined_array_nonSS[1:count_nonSS, :];\n",
    "combined_array_SS = sort!(combined_array_SS[1:count_SS, :],dims=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "modular-trunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delete_duplicates (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function delete_duplicates(matrix)\n",
    "    unique_matrix = Matrix{Any}(undef, length(matrix[:,1]), 16)\n",
    "    row_count = 1\n",
    "    \n",
    "    # enter first row\n",
    "    unique_matrix[row_count, :] = matrix[1, :]\n",
    "    for i in 2:length(matrix[:,1])\n",
    "        is_duplicate = false\n",
    "    \n",
    "        # Check if the row is a duplicate in the unique DataFrame\n",
    "        for j in 1:row_count\n",
    "            if matrix[i,1] == unique_matrix[j,1]\n",
    "                is_duplicate = true\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # If not a duplicate, append it to the unique DataFrame\n",
    "        if !is_duplicate\n",
    "            row_count += 1\n",
    "            unique_matrix[row_count, :] = matrix[i, :]\n",
    "        end\n",
    "\n",
    "    end\n",
    "\n",
    "    # Remove undef elements\n",
    "    unique_matrix = unique_matrix[1:row_count, :];\n",
    "    return unique_matrix\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "apart-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95661, 16)\n"
     ]
    }
   ],
   "source": [
    "unique_matrix = delete_duplicates(combined_array_SS)\n",
    "println(size(unique_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "desperate-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133237, 16)\n"
     ]
    }
   ],
   "source": [
    "unique_matrix = delete_duplicates_reverse(combined_array)\n",
    "println(size(unique_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-treaty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "affiliated-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35318, 17)\n",
      "35290\n",
      "54710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/home/dauenha0/murp1677/Cyclic_Dynamics/Batch_Scripts/Parameters/ReRuns_Set2_new.csv\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Parameters to re-run\n",
    "\n",
    "# Load data sets\n",
    "fileName = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/Set2_Simulation_outputs.csv\"\n",
    "df = CSV.read(fileName, DataFrame);\n",
    "df = sort!(df)\n",
    "println(size(df))\n",
    "\n",
    "# Convert DataFrame to an array of tuples\n",
    "run_tuples = Set([(row[1], row[2]) for row in eachrow(df)])\n",
    "\n",
    "Simulations_run = run_tuples\n",
    "\n",
    "# Initialize a list to store missing combinations\n",
    "missing_combinations = []\n",
    "\n",
    "# Loop through all possible combinations\n",
    "for i in 1:1500\n",
    "    for j in 1:60\n",
    "        if (i, j) ∉ Simulations_run\n",
    "            push!(missing_combinations, (i, j))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# Display missing combinations\n",
    "println(length(Simulations_run))\n",
    "println(length(missing_combinations))\n",
    "\n",
    "# Write missing combinations to a CSV file\n",
    "missing_combinations_df = DataFrame(BatchID = [x[1] for x in missing_combinations], SimID = [x[2] for x in missing_combinations])\n",
    "CSV.write(\"/home/dauenha0/murp1677/Cyclic_Dynamics/Batch_Scripts/Parameters/ReRuns_Set2_new.csv\", missing_combinations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "naughty-purchase",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2023-09-05_Simulation_outputs_Set1.csv\" is not a valid file or doesn't exist",
     "output_type": "error",
     "traceback": [
      "ArgumentError: \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2023-09-05_Simulation_outputs_Set1.csv\" is not a valid file or doesn't exist",
      "",
      "Stacktrace:",
      " [1] CSV.Context(source::CSV.Arg, header::CSV.Arg, normalizenames::CSV.Arg, datarow::CSV.Arg, skipto::CSV.Arg, footerskip::CSV.Arg, transpose::CSV.Arg, comment::CSV.Arg, ignoreemptyrows::CSV.Arg, ignoreemptylines::CSV.Arg, select::CSV.Arg, drop::CSV.Arg, limit::CSV.Arg, buffer_in_memory::CSV.Arg, threaded::CSV.Arg, ntasks::CSV.Arg, tasks::CSV.Arg, rows_to_check::CSV.Arg, lines_to_check::CSV.Arg, missingstrings::CSV.Arg, missingstring::CSV.Arg, delim::CSV.Arg, ignorerepeated::CSV.Arg, quoted::CSV.Arg, quotechar::CSV.Arg, openquotechar::CSV.Arg, closequotechar::CSV.Arg, escapechar::CSV.Arg, dateformat::CSV.Arg, dateformats::CSV.Arg, decimal::CSV.Arg, truestrings::CSV.Arg, falsestrings::CSV.Arg, stripwhitespace::CSV.Arg, type::CSV.Arg, types::CSV.Arg, typemap::CSV.Arg, pool::CSV.Arg, downcast::CSV.Arg, lazystrings::CSV.Arg, stringtype::CSV.Arg, strict::CSV.Arg, silencewarnings::CSV.Arg, maxwarnings::CSV.Arg, debug::CSV.Arg, parsingdebug::CSV.Arg, validate::CSV.Arg, streaming::CSV.Arg)",
      "   @ CSV ~/.julia/packages/CSV/7lFhM/src/context.jl:306",
      " [2] #File#28",
      "   @ ~/.julia/packages/CSV/7lFhM/src/file.jl:221 [inlined]",
      " [3] CSV.File(source::String)",
      "   @ CSV ~/.julia/packages/CSV/7lFhM/src/file.jl:162",
      " [4] read(source::String, sink::Type; copycols::Bool, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "   @ CSV ~/.julia/packages/CSV/7lFhM/src/CSV.jl:117",
      " [5] read(source::String, sink::Type)",
      "   @ CSV ~/.julia/packages/CSV/7lFhM/src/CSV.jl:113",
      " [6] top-level scope",
      "   @ In[13]:5"
     ]
    }
   ],
   "source": [
    "# Find Parameters that were ran\n",
    "\n",
    "# Load data sets\n",
    "fileName = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2023-09-05_Simulation_outputs_Set1.csv\"\n",
    "df = CSV.read(fileName, DataFrame);\n",
    "df = sort!(df)\n",
    "#println((df))\n",
    "\n",
    "# Convert DataFrame to an array of tuples\n",
    "run_tuples = Set([(row[1], row[2]) for row in eachrow(df)])\n",
    "\n",
    "Simulations_run1 = run_tuples\n",
    "\n",
    "#println(Simulations_run1)\n",
    "\n",
    "# Find Parameters that were ran\n",
    "\n",
    "# Load data sets\n",
    "fileName = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2023-09-05_Simulation_outputs_Set2.csv\"\n",
    "df = CSV.read(fileName, DataFrame);\n",
    "df = sort!(df)\n",
    "#println(size(df))\n",
    "\n",
    "# Convert DataFrame to an array of tuples\n",
    "#run_tuples = Set([(row[1], row[2]) for row in eachrow(df)])\n",
    "\n",
    "#Simulations_run2 = run_tuples\n",
    "\n",
    "#println(length(Simulations_run1)+length(Simulations_run2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "decreased-cruise",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: \u001b[0mCannot `convert` an object of type \n\u001b[0m  \u001b[92mDataFrame\u001b[39m\u001b[0m to an object of type \n\u001b[0m  \u001b[91mMatrix\u001b[39m\n\n\u001b[0mClosest candidates are:\n\u001b[0m  convert(::Type{T}, \u001b[91m::LinearAlgebra.Factorization\u001b[39m) where T<:AbstractArray\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mLinearAlgebra\u001b[39m \u001b[90m/panfs/jay/groups/16/dauenha0/murp1677/Julia_Nest/julia-1.9.0/share/julia/stdlib/v1.9/LinearAlgebra/src/\u001b[39m\u001b[90m\u001b[4mfactorization.jl:59\u001b[24m\u001b[39m\n\u001b[0m  convert(::Type{Matrix}, \u001b[91m::PooledArrays.PooledMatrix{T, R}\u001b[39m) where {T, R}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mPooledArrays\u001b[39m \u001b[90m~/.julia/packages/PooledArrays/DXlaI/src/\u001b[39m\u001b[90m\u001b[4mPooledArrays.jl:511\u001b[24m\u001b[39m\n\u001b[0m  convert(::Type{T}, \u001b[91m::AbstractArray\u001b[39m) where T<:Array\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4marray.jl:613\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: \u001b[0mCannot `convert` an object of type \n\u001b[0m  \u001b[92mDataFrame\u001b[39m\u001b[0m to an object of type \n\u001b[0m  \u001b[91mMatrix\u001b[39m\n\n\u001b[0mClosest candidates are:\n\u001b[0m  convert(::Type{T}, \u001b[91m::LinearAlgebra.Factorization\u001b[39m) where T<:AbstractArray\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mLinearAlgebra\u001b[39m \u001b[90m/panfs/jay/groups/16/dauenha0/murp1677/Julia_Nest/julia-1.9.0/share/julia/stdlib/v1.9/LinearAlgebra/src/\u001b[39m\u001b[90m\u001b[4mfactorization.jl:59\u001b[24m\u001b[39m\n\u001b[0m  convert(::Type{Matrix}, \u001b[91m::PooledArrays.PooledMatrix{T, R}\u001b[39m) where {T, R}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mPooledArrays\u001b[39m \u001b[90m~/.julia/packages/PooledArrays/DXlaI/src/\u001b[39m\u001b[90m\u001b[4mPooledArrays.jl:511\u001b[24m\u001b[39m\n\u001b[0m  convert(::Type{T}, \u001b[91m::AbstractArray\u001b[39m) where T<:Array\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4marray.jl:613\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[29]:6"
     ]
    }
   ],
   "source": [
    "# Separate Steady State and Non-Steady State\n",
    "\n",
    "# Load data sets\n",
    "fileName = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/Set1_Simulation_outputs.csv\"\n",
    "df = CSV.read(fileName, DataFrame);\n",
    "df_array = convert(Matrix,df)\n",
    "\n",
    "BatchID = df_array[:,1];\n",
    "SimID = df_array[:,2];\n",
    "SS_confirmation = df_array[:,17]\n",
    "SS_runs = []\n",
    "\n",
    "\n",
    "for i in range(1,length(df_array[:,1]))\n",
    "    if df_array[i,17] == true\n",
    "        # Steady State is reached\n",
    "        # Create DataFrame to export parameters to Steady State CSV\n",
    "        data = df_array[i:i,:]\n",
    "        push!(SS_runs, data)\n",
    "    else\n",
    "        # Steady State is NOT reached\n",
    "        # Create DataFrame to export parameters to Non-Steady State CSV\n",
    "        fpath_nonSS = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2023-09-12_Simulation_outputs_Set1_Non_SteadyState.csv\"\n",
    "        data = df_array[i:i,:]\n",
    "        if isfile(fpath_nonSS) == false # checks if file exists\n",
    "        # if file does NOT exist, write file and include column names\n",
    "            col_names = [\"Batch ID\",\"Simulation ID\", \"alpha a\", \"alpha b\", \"alpha c\", \"beta a\", \"beta b\", \"beta c\", \"gamma B-A\", \"gamma C-A\", \"delta B-A\", \"delta C-A\", \"BEa\", \"frequency [1/s]\", \"ΔBEa [eV]\", \"Loop TOF [1/s]\",\"Steady State Conditon\"];\n",
    "            CSV.write(fpath_nonSS, data, header=col_names)\n",
    "        else \n",
    "            CSV.write(fpath_nonSS, data, append=true)\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store SS data\n",
    "SS_runs = sort(union(SS_runs))\n",
    "fpathSS = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2023-09-07_Simulation_outputs_Set1.csv\"\n",
    "if isfile(fpathSS) == false # checks if file exists\n",
    "    # if file does NOT exist, write file and include column names\n",
    "    col_names = [\"Batch ID\",\"Simulation ID\", \"alpha a\", \"alpha b\", \"alpha c\", \"beta a\", \"beta b\", \"beta c\", \"gamma B-A\", \"gamma C-A\", \"delta B-A\", \"delta C-A\", \"BEa\", \"frequency [1/s]\", \"ΔBEa [eV]\", \"Loop TOF [1/s]\",\"Steady State Conditon\"];\n",
    "    CSV.write(fpathSS, data, header=col_names)\n",
    "else \n",
    "    CSV.write(fpathSS, data, append=true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "widespread-disney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29481\n",
      "28828\n"
     ]
    }
   ],
   "source": [
    "# Load data sets\n",
    "fileName = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/2023-09-07_Simulation_outputs_Set1.csv\"\n",
    "df = CSV.read(fileName, DataFrame);\n",
    "\n",
    "BatchID = df[:,1];\n",
    "SimID = df[:,2];\n",
    "\n",
    "println(length(BatchID))\n",
    "\n",
    "\n",
    "run_tuples = Set([(row[1], row[2]) for row in eachrow(df)])\n",
    "println(length(run_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "above-sugar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mthread = 1 warning: only found 2 / 17 columns around data row: 54. Filling remaining columns with `missing`\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ CSV ~/.julia/packages/CSV/7lFhM/src/file.jl:576\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mthread = 1 warning: only found 2 / 17 columns around data row: 54. Filling remaining columns with `missing`\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ CSV ~/.julia/packages/CSV/7lFhM/src/file.jl:576\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/SimulationOutputSet1/results_Batch1485-NEW.csv\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete lines not wanted\n",
    "\n",
    "# Load data sets\n",
    "fileName = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/SimulationOutputSet1/results_Batch1485.csv\"\n",
    "df = CSV.read(fileName, DataFrame);\n",
    "\n",
    "df = delete!(df, [54])\n",
    "\n",
    "output_file = \"/home/dauenha0/murp1677/Cyclic_Dynamics/Results/SimulationOutputSet1/results_Batch1485-NEW.csv\"\n",
    "# Write the contents to the output CSV file\n",
    "        if isfile(output_file) == false\n",
    "            # If the file does not exst, write the file including column names\n",
    "            col_names = [\"Batch ID\",\"Simulation ID\", \"alpha a\", \"alpha b\", \"alpha c\", \"beta a\", \"beta b\", \n",
    "                \"beta c\", \"gamma B-A\", \"gamma C-A\", \"delta B-A\", \"delta C-A\", \"BEa\", \"frequency [1/s]\", \n",
    "                \"ΔBEa [eV]\", \"Loop TOF [1/s]\",\"Steady State Conditon\"]; # 17 columns\n",
    "            CSV.write(output_file, df, header=col_names)\n",
    "        else    \n",
    "            CSV.write(output_file, df, append=true)\n",
    "        end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-means",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
